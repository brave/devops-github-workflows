name: Cleanup S3 buckets from deployed pr subfolders

on:
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
    secrets:
      S3_BUCKET_NAME:
        required: true
      AWS_ROLE_ARN:
        required: true
      AWS_REGION:
        required: true

jobs:
  cleanup:
    name: cleanup
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read # This is required for actions/checkout
      pull-requests: read
    environment:
      name: ${{ inputs.environment }}
    env:
      S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}

    steps:
      - name: Configure aws credentials
        uses: aws-actions/configure-aws-credentials@5fd3084fc36e372ff1fff382a39b10d03659f355 # v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          role-session-name: github-actions-basicattentiontoken-org-${{ github.triggering_actor }}-${{ github.run_id }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Cleanup
        uses: actions/github-script@d7906e4ad0b1822421a7e6a35d5ca353c962f410 # v6
        with:
          retries: 10
          script: |
            const AWS = 'aws'
            const BUCKET = '${{ secrets.S3_BUCKET_NAME }}'
            const PREFIX_SELECTOR = 'pr-'
            const AWS_LS_ARGS = ['s3', 'ls', `s3://${BUCKET}/${PREFIX_SELECTOR}`]
            let aws_out = '';

            await exec.exec(AWS, ['configure', 'set', 'default.s3.max_concurrent_requests', '100']);
            await exec.exec(AWS, ['configure', 'set', 'default.s3.max_queue_size', '10000']);

            const options = {ignoreReturnCode: true};
            options.listeners = {
              stdout: (data) => {
                aws_out += data.toString();
              },
            };

            async function is_not_open(pr) {
                let res = await github.rest.pulls.get({
                    pull_number: pr,
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                })
                return res.data.state !== "open"
            }

            const ls_res = await exec.exec(AWS, AWS_LS_ARGS, options);
            if (ls_res !== 0) { console.log("No garbage found. Exiting"); process.exit(); }

            const pr_regex = /PRE pr-(\d+)\//g
            const results = aws_out.matchAll(pr_regex);
            let pr_buckets = [];
            for(let result of results) {
              pr_buckets.push(result[1])
            }

            const asyncFilter = (arr, predicate) => Promise.all(arr.map(predicate)).then((results) => arr.filter((_v, index) => results[index]));
            const prefixes_to_delete = await asyncFilter(pr_buckets, is_not_open)
            console.log("To be deleted", prefixes_to_delete)

            for (const pr of prefixes_to_delete) {
              console.log(`::group::Deleting ${PREFIX_SELECTOR}${pr}`)
              const AWS_RM_ARGS = ['s3', 'rm', '--recursive', `s3://${BUCKET}/${PREFIX_SELECTOR}${pr}`]
              await exec.exec(AWS, AWS_RM_ARGS);
              console.log('::endgroup::')
            }
